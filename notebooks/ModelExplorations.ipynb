{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import models\n",
    "import generation_utils\n",
    "import metrics_utils\n",
    "import tokenizer\n",
    "import data_utils\n",
    "from utils import get_best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 999)\n",
    "pd.set_option('display.max_rows', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../models/base_24_2^18/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model at ../models/base_24_2^18/checkpoints/730000_0.1004.pt\n"
     ]
    }
   ],
   "source": [
    "checkpoint = get_best_checkpoint(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = checkpoint['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer.Tokenizer(base = args['data']['base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'model_args', 'optimizer', 'scheduler', 'loader', 'io', 'metrics', 'multi_gpu', 'verbose', 'tokenizer'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Factorizer(\n",
       "  (embedding): TransformerEmbedding(\n",
       "    (embedding): Embedding(28, 128)\n",
       "    (pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (tokens_out): Linear(in_features=128, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Factorizer(n_tokens = args['tokenizer']['n_tokens'], \n",
    "                          pad_token_id = args['tokenizer']['pad_token_id'],\n",
    "                          **args['model_args'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.embedding.embedding.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [''.join(t.decode([i], decode_special=True)) for i in range(len(t))]\n",
    "special_tokens = set(['x', '_', '>', '.'])\n",
    "tokens = np.array([tok if tok in special_tokens else data_utils.base2dec([int(tok)], args['data']['base']) for tok in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
       "       'x', '_', '.', '>'], dtype='<U11')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE\n",
    "* Doesn't seem to be super interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=30, learning_rate=200, n_iter=1000)\n",
    "embeddings_for_plot = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(embeddings_for_plot[:,0], embeddings_for_plot[:,1])\n",
    "ax = plt.gca()\n",
    "for tok, (x,y) in zip(tokens, embeddings_for_plot):\n",
    "    fontsize = 12 if not tok in ['.', '_'] else 24\n",
    "    ax.annotate(tok, (x+.3,y), fontsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "* Some embeddings have relatively simlar cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_sim_mat = cosine_similarity(embeddings)\n",
    "cs_sims = np.triu(cs_sim_mat, 1).ravel()\n",
    "cs_sims = cs_sims[~np.isclose(cs_sims, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('cosine simiarlty of embeddings')\n",
    "pd.Series(cs_sims).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_sim_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000001 ,  0.20947157,  0.12409612,  0.09352618,  0.14274287,\n",
       "         0.1483083 ,  0.25185296,  0.1967082 ,  0.09906537,  0.07954345,\n",
       "         0.24456161,  0.07309192,  0.24926093,  0.12558152,  0.09385978,\n",
       "        -0.01023844,  0.19143035,  0.09078324,  0.14960185,  0.15796833,\n",
       "         0.06624856,  0.21853077,  0.22200237,  0.0095817 ,  0.28712404,\n",
       "         0.01520046,  0.20431857,  0.23378865],\n",
       "       [ 0.20947157,  1.        ,  0.40349138,  0.2897607 ,  0.30031124,\n",
       "         0.3908712 ,  0.28289518,  0.41249555,  0.23237519,  0.17732228,\n",
       "         0.22023821,  0.25866315,  0.14750424,  0.3370837 ,  0.14793764,\n",
       "         0.2015448 ,  0.24701005,  0.30432042,  0.16685933,  0.17232986,\n",
       "         0.08069484,  0.3746502 ,  0.21636525,  0.21139815,  0.6191268 ,\n",
       "        -0.04172302,  0.48982775,  0.53016627],\n",
       "       [ 0.12409612,  0.40349138,  1.        ,  0.27189764,  0.10707545,\n",
       "         0.26574343,  0.14032036,  0.22256562,  0.09540227,  0.1540948 ,\n",
       "         0.15306129,  0.20488922,  0.12852323,  0.18972673,  0.20910439,\n",
       "         0.04408801,  0.14129885,  0.17338112,  0.14713901,  0.1640355 ,\n",
       "         0.03825084,  0.22870564,  0.08927051,  0.13609731,  0.43899453,\n",
       "         0.02761384,  0.31527936,  0.33706266],\n",
       "       [ 0.09352618,  0.2897607 ,  0.27189764,  1.        ,  0.19526474,\n",
       "         0.23446918,  0.1117919 ,  0.18274307,  0.10250018,  0.09431785,\n",
       "         0.17850931,  0.20874752,  0.08699354,  0.183396  ,  0.08725149,\n",
       "         0.07307315,  0.10202339,  0.16966046,  0.08499385,  0.1946918 ,\n",
       "         0.09950116,  0.17844416,  0.10297389,  0.11138918,  0.33669603,\n",
       "         0.12185474,  0.21948026,  0.26621434],\n",
       "       [ 0.14274287,  0.30031124,  0.10707545,  0.19526474,  0.9999999 ,\n",
       "         0.12286445,  0.14147976,  0.12402454,  0.06708802,  0.0116087 ,\n",
       "         0.11932708,  0.04250678,  0.03530895,  0.1399392 ,  0.08931457,\n",
       "         0.04621067,  0.13974383,  0.16260181,  0.0208268 , -0.02701467,\n",
       "         0.18183126,  0.10837617,  0.17735282,  0.08469234,  0.21898068,\n",
       "         0.02466346,  0.23688842,  0.20740552],\n",
       "       [ 0.1483083 ,  0.3908712 ,  0.26574343,  0.23446918,  0.12286445,\n",
       "         1.        ,  0.14840992,  0.26597962,  0.08582522,  0.08686334,\n",
       "         0.184078  ,  0.222776  ,  0.06050637,  0.25910887,  0.15600479,\n",
       "         0.07982249,  0.06813941,  0.27807465,  0.13731773,  0.11784767,\n",
       "        -0.0359689 ,  0.18375   ,  0.05034522,  0.12839618,  0.40003356,\n",
       "        -0.00538185,  0.28363562,  0.33249944],\n",
       "       [ 0.25185296,  0.28289518,  0.14032036,  0.1117919 ,  0.14147976,\n",
       "         0.14840992,  1.0000002 ,  0.19305585,  0.16183843,  0.1106097 ,\n",
       "         0.21385732,  0.17951098,  0.12607014,  0.11845329,  0.08567219,\n",
       "         0.1332639 ,  0.1534951 ,  0.13563514,  0.15803812,  0.065749  ,\n",
       "         0.08174513,  0.26472902,  0.14901769,  0.02461082,  0.24340203,\n",
       "        -0.1176398 ,  0.17348135,  0.23697512],\n",
       "       [ 0.1967082 ,  0.41249555,  0.22256562,  0.18274307,  0.12402454,\n",
       "         0.26597962,  0.19305585,  0.9999999 ,  0.05569057,  0.08431202,\n",
       "         0.20835154,  0.2602974 ,  0.16770735,  0.33650774,  0.07610771,\n",
       "         0.14423075,  0.15584262,  0.19789109,  0.14418638,  0.3065075 ,\n",
       "         0.04238791,  0.23613745,  0.11006624,  0.15094781,  0.37706512,\n",
       "        -0.04354885,  0.2903532 ,  0.36218962],\n",
       "       [ 0.09906537,  0.23237519,  0.09540227,  0.10250018,  0.06708802,\n",
       "         0.08582522,  0.16183843,  0.05569057,  0.99999964,  0.13137235,\n",
       "         0.09950217,  0.17884837,  0.111536  ,  0.10812847,  0.03781361,\n",
       "        -0.07162542,  0.2007436 ,  0.06519639,  0.08465089, -0.04075289,\n",
       "         0.13838005,  0.06670558,  0.00965252,  0.01360961,  0.2067768 ,\n",
       "         0.01164979,  0.19709404,  0.20789756],\n",
       "       [ 0.07954345,  0.17732228,  0.1540948 ,  0.09431785,  0.0116087 ,\n",
       "         0.08686334,  0.1106097 ,  0.08431202,  0.13137235,  0.99999994,\n",
       "         0.11229281,  0.15543209,  0.06064254,  0.10045186,  0.05967433,\n",
       "         0.23512354,  0.04982447,  0.07547863,  0.1658694 ,  0.12090158,\n",
       "        -0.00736789,  0.24643523,  0.04914093,  0.03197335,  0.26110983,\n",
       "         0.04759899,  0.22873901,  0.17147088],\n",
       "       [ 0.24456161,  0.22023821,  0.15306129,  0.17850931,  0.11932708,\n",
       "         0.184078  ,  0.21385732,  0.20835154,  0.09950217,  0.11229281,\n",
       "         1.0000002 ,  0.1368713 ,  0.166891  ,  0.19278656,  0.14693728,\n",
       "         0.1412825 ,  0.22864833,  0.12393504,  0.20556879,  0.14397797,\n",
       "         0.0098139 ,  0.13655159,  0.33932188,  0.07421035,  0.2624838 ,\n",
       "         0.03380999,  0.25268927,  0.18289994],\n",
       "       [ 0.07309192,  0.25866315,  0.20488922,  0.20874752,  0.04250678,\n",
       "         0.222776  ,  0.17951098,  0.2602974 ,  0.17884837,  0.15543209,\n",
       "         0.1368713 ,  1.0000001 ,  0.10029259,  0.20891313,  0.01491767,\n",
       "         0.1421955 ,  0.13237838,  0.21695578,  0.11525924,  0.23946172,\n",
       "        -0.0686678 ,  0.17473496,  0.07760565,  0.12676865,  0.29953182,\n",
       "         0.04081982,  0.26955405,  0.26787513],\n",
       "       [ 0.24926093,  0.14750424,  0.12852323,  0.08699354,  0.03530895,\n",
       "         0.06050637,  0.12607014,  0.16770735,  0.111536  ,  0.06064254,\n",
       "         0.166891  ,  0.10029259,  1.0000002 ,  0.19949026,  0.08474524,\n",
       "         0.08712251,  0.1845557 ,  0.10013866,  0.12175778,  0.07118213,\n",
       "         0.06826428,  0.09519367,  0.12657034,  0.03634037,  0.14793953,\n",
       "         0.02574844,  0.20426327,  0.09683776],\n",
       "       [ 0.12558152,  0.3370837 ,  0.18972673,  0.183396  ,  0.1399392 ,\n",
       "         0.25910887,  0.11845329,  0.33650774,  0.10812847,  0.10045186,\n",
       "         0.19278656,  0.20891313,  0.19949026,  1.        ,  0.08803908,\n",
       "         0.17350395,  0.20095788,  0.16535644,  0.12546937,  0.24885693,\n",
       "         0.01956956,  0.24487764,  0.20760037,  0.18911634,  0.41761228,\n",
       "        -0.04800564,  0.32866627,  0.37237516],\n",
       "       [ 0.09385978,  0.14793764,  0.20910439,  0.08725149,  0.08931457,\n",
       "         0.15600479,  0.08567219,  0.07610771,  0.03781361,  0.05967433,\n",
       "         0.14693728,  0.01491767,  0.08474524,  0.08803908,  1.0000001 ,\n",
       "         0.0858279 ,  0.13037182,  0.00379227,  0.20022035,  0.02919539,\n",
       "         0.1241031 ,  0.14658716,  0.11117861, -0.01923   ,  0.1915569 ,\n",
       "        -0.05340821,  0.17601697,  0.15600637],\n",
       "       [-0.01023844,  0.2015448 ,  0.04408801,  0.07307315,  0.04621067,\n",
       "         0.07982249,  0.1332639 ,  0.14423075, -0.07162542,  0.23512354,\n",
       "         0.1412825 ,  0.1421955 ,  0.08712251,  0.17350395,  0.0858279 ,\n",
       "         1.0000001 ,  0.19111015,  0.14457151,  0.13526133,  0.12557417,\n",
       "        -0.02806742,  0.27281424,  0.14533767,  0.05411454,  0.23093116,\n",
       "        -0.14585204,  0.18624312,  0.1587582 ],\n",
       "       [ 0.19143035,  0.24701005,  0.14129885,  0.10202339,  0.13974383,\n",
       "         0.06813941,  0.1534951 ,  0.15584262,  0.2007436 ,  0.04982447,\n",
       "         0.22864833,  0.13237838,  0.1845557 ,  0.20095788,  0.13037182,\n",
       "         0.19111015,  1.0000001 ,  0.10585708,  0.14554696,  0.13499673,\n",
       "         0.13677709,  0.18138091,  0.23970072,  0.0852356 ,  0.2972509 ,\n",
       "         0.0054539 ,  0.27746713,  0.27140749],\n",
       "       [ 0.09078324,  0.30432042,  0.17338112,  0.16966046,  0.16260181,\n",
       "         0.27807465,  0.13563514,  0.19789109,  0.06519639,  0.07547863,\n",
       "         0.12393504,  0.21695578,  0.10013866,  0.16535644,  0.00379227,\n",
       "         0.14457151,  0.10585708,  1.        ,  0.10457897,  0.18654618,\n",
       "         0.03996856,  0.1787034 ,  0.10610088,  0.15286629,  0.2888998 ,\n",
       "        -0.05961173,  0.22942047,  0.23266558],\n",
       "       [ 0.14960185,  0.16685933,  0.14713901,  0.08499385,  0.0208268 ,\n",
       "         0.13731773,  0.15803812,  0.14418638,  0.08465089,  0.1658694 ,\n",
       "         0.20556879,  0.11525924,  0.12175778,  0.12546937,  0.20022035,\n",
       "         0.13526133,  0.14554696,  0.10457897,  1.0000001 ,  0.16297933,\n",
       "         0.09375498,  0.18285021,  0.30821404,  0.06989716,  0.3142658 ,\n",
       "         0.01600098,  0.27858981,  0.23312119],\n",
       "       [ 0.15796833,  0.17232986,  0.1640355 ,  0.1946918 , -0.02701467,\n",
       "         0.11784767,  0.065749  ,  0.3065075 , -0.04075289,  0.12090158,\n",
       "         0.14397797,  0.23946172,  0.07118213,  0.24885693,  0.02919539,\n",
       "         0.12557417,  0.13499673,  0.18654618,  0.16297933,  0.9999999 ,\n",
       "        -0.04774092,  0.14226677,  0.02932017,  0.15893044,  0.28173926,\n",
       "        -0.04623825,  0.24166335,  0.2530193 ],\n",
       "       [ 0.06624856,  0.08069484,  0.03825084,  0.09950116,  0.18183126,\n",
       "        -0.0359689 ,  0.08174513,  0.04238791,  0.13838005, -0.00736789,\n",
       "         0.0098139 , -0.0686678 ,  0.06826428,  0.01956956,  0.1241031 ,\n",
       "        -0.02806742,  0.13677709,  0.03996856,  0.09375498, -0.04774092,\n",
       "         1.        ,  0.17083758,  0.21948084, -0.01311875,  0.10349505,\n",
       "         0.0059579 ,  0.1293372 ,  0.11549101],\n",
       "       [ 0.21853077,  0.3746502 ,  0.22870564,  0.17844416,  0.10837617,\n",
       "         0.18375   ,  0.26472902,  0.23613745,  0.06670558,  0.24643523,\n",
       "         0.13655159,  0.17473496,  0.09519367,  0.24487764,  0.14658716,\n",
       "         0.27281424,  0.18138091,  0.1787034 ,  0.18285021,  0.14226677,\n",
       "         0.17083758,  1.0000001 ,  0.24657509,  0.20730998,  0.4916681 ,\n",
       "        -0.00562446,  0.49127892,  0.5260643 ],\n",
       "       [ 0.22200237,  0.21636525,  0.08927051,  0.10297389,  0.17735282,\n",
       "         0.05034522,  0.14901769,  0.11006624,  0.00965252,  0.04914093,\n",
       "         0.33932188,  0.07760565,  0.12657034,  0.20760037,  0.11117861,\n",
       "         0.14533767,  0.23970072,  0.10610088,  0.30821404,  0.02932017,\n",
       "         0.21948084,  0.24657509,  0.9999999 ,  0.14676544,  0.2556912 ,\n",
       "        -0.04085009,  0.2613053 ,  0.21206565],\n",
       "       [ 0.0095817 ,  0.21139815,  0.13609731,  0.11138918,  0.08469234,\n",
       "         0.12839618,  0.02461082,  0.15094781,  0.01360961,  0.03197335,\n",
       "         0.07421035,  0.12676865,  0.03634037,  0.18911634, -0.01923   ,\n",
       "         0.05411454,  0.0852356 ,  0.15286629,  0.06989716,  0.15893044,\n",
       "        -0.01311875,  0.20730998,  0.14676544,  0.99999994,  0.18196984,\n",
       "        -0.13177478,  0.18756601,  0.17891267],\n",
       "       [ 0.28712404,  0.6191268 ,  0.43899453,  0.33669603,  0.21898068,\n",
       "         0.40003356,  0.24340203,  0.37706512,  0.2067768 ,  0.26110983,\n",
       "         0.2624838 ,  0.29953182,  0.14793953,  0.41761228,  0.1915569 ,\n",
       "         0.23093116,  0.2972509 ,  0.2888998 ,  0.3142658 ,  0.28173926,\n",
       "         0.10349505,  0.4916681 ,  0.2556912 ,  0.18196984,  0.9999998 ,\n",
       "         0.08932981,  0.74765915,  0.73432213],\n",
       "       [ 0.01520046, -0.04172302,  0.02761384,  0.12185474,  0.02466346,\n",
       "        -0.00538185, -0.1176398 , -0.04354885,  0.01164979,  0.04759899,\n",
       "         0.03380999,  0.04081982,  0.02574844, -0.04800564, -0.05340821,\n",
       "        -0.14585204,  0.0054539 , -0.05961173,  0.01600098, -0.04623825,\n",
       "         0.0059579 , -0.00562446, -0.04085009, -0.13177478,  0.08932981,\n",
       "         1.        ,  0.26140115,  0.0486665 ],\n",
       "       [ 0.20431857,  0.48982775,  0.31527936,  0.21948026,  0.23688842,\n",
       "         0.28363562,  0.17348135,  0.2903532 ,  0.19709404,  0.22873901,\n",
       "         0.25268927,  0.26955405,  0.20426327,  0.32866627,  0.17601697,\n",
       "         0.18624312,  0.27746713,  0.22942047,  0.27858981,  0.24166335,\n",
       "         0.1293372 ,  0.49127892,  0.2613053 ,  0.18756601,  0.74765915,\n",
       "         0.26140115,  1.        ,  0.6637792 ],\n",
       "       [ 0.23378865,  0.53016627,  0.33706266,  0.26621434,  0.20740552,\n",
       "         0.33249944,  0.23697512,  0.36218962,  0.20789756,  0.17147088,\n",
       "         0.18289994,  0.26787513,  0.09683776,  0.37237516,  0.15600637,\n",
       "         0.1587582 ,  0.27140749,  0.23266558,  0.23312119,  0.2530193 ,\n",
       "         0.11549101,  0.5260643 ,  0.21206565,  0.17891267,  0.73432213,\n",
       "         0.0486665 ,  0.6637792 ,  0.9999999 ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41249555"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_show_mat[mat_show_mat<.99].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat_show_mat = cs_sim_mat[:-4,:-4]\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 20)\n",
    "ax = plt.gca()\n",
    "plt.colorbar(ax.matshow(np.clip(mat_show_mat, a_min=-1, a_max=mat_show_mat[mat_show_mat<.99].max()*1.1)), ax=ax)\n",
    "ax.set_xticks(np.arange(mat_show_mat.shape[0]))\n",
    "ax.set_yticks(np.arange(mat_show_mat.shape[0]))\n",
    "ax.set_xticklabels(tokens[:mat_show_mat.shape[0]])\n",
    "ax.set_yticklabels(tokens[:mat_show_mat.shape[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0999999344348907"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_sim_mat[cs_sim_mat<1].max()*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C = .1, penalty='l1', solver='liblinear')\n",
    "# logreg = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 128), (28,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_x = embeddings[:-4]\n",
    "logreg_y = tokens[:-4].astype(int) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexer = np.random.rand(logreg_x.shape[0]) < .8\n",
    "logreg_x_train = logreg_x[train_indexer]\n",
    "logreg_x_test = logreg_x[~train_indexer]\n",
    "\n",
    "logreg_y_train = logreg_y[train_indexer]\n",
    "logreg_y_test = logreg_y[~train_indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 128), (17,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_x_train.shape, logreg_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 128), (7,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_x_test.shape, logreg_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(logreg_x_train, logreg_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(logreg_x_test, logreg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How well does the model do on numbers higher than what it was trained on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2**18\n",
    "length = 4096\n",
    "numbers = np.arange(start, start + length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generation_utils' from '../src\\\\generation_utils.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(metrics_utils)\n",
    "importlib.reload(generation_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizer.Tokenizer at 0x2cb5a1daf70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4096.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "larger_df = metrics_utils.form_factor_df(model, t, device, args['data']['base'], numbers, args['model_args']['max_decode_size'], postprocess_minimal=True, n_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40960, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larger_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_num</th>\n",
       "      <th>beam_idx</th>\n",
       "      <th>log_prob</th>\n",
       "      <th>pred_factor_list</th>\n",
       "      <th>product</th>\n",
       "      <th>correct_product</th>\n",
       "      <th>correct_factorization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65536</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.182287</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 23]</td>\n",
       "      <td>94208</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.500107</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5]</td>\n",
       "      <td>81920</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65536</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.718703</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>65536</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65536</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.779272</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5]</td>\n",
       "      <td>163840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65536</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.797647</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 17]</td>\n",
       "      <td>69632</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_num  beam_idx  log_prob  \\\n",
       "0       65536         0 -2.182287   \n",
       "1       65536         1 -2.500107   \n",
       "2       65536         2 -2.718703   \n",
       "3       65536         3 -2.779272   \n",
       "4       65536         4 -2.797647   \n",
       "\n",
       "                                   pred_factor_list  product  correct_product  \\\n",
       "0          [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 23]    94208            False   \n",
       "1     [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5]    81920            False   \n",
       "2  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]    65536             True   \n",
       "3  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5]   163840            False   \n",
       "4          [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 17]    69632            False   \n",
       "\n",
       "   correct_factorization  \n",
       "0                  False  \n",
       "1                  False  \n",
       "2                   True  \n",
       "3                  False  \n",
       "4                  False  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larger_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct_factorization    0.898926\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larger_df.groupby('target_num').agg({'correct_factorization' : 'any'}).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.370849609375"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_beams = larger_df['beam_idx'] == 9\n",
    "(larger_df[top_beams]['product'] < larger_df[top_beams]['target_num']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function generation_utils.factor(number, base, model, tokenizer, device, max_decode_size, n_beams=1, temperature=1.0, return_type='df', postprocess_minimal=False)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_utils.factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import factorint\n",
    "from sympy.ntheory import primerange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  9, 25, 49], dtype=int32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(primerange(2, 10)))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = 1223*1223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1223: 2}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorint(test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how does it handle squares/cubes/...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 100\n",
    "squares = np.array(list(primerange(2, max_num)))**2\n",
    "cubes = np.array(list(primerange(2, max_num)))**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "square_df = metrics_utils.form_factor_df(model, t, device, args['data']['base'], squares, args['model_args']['max_decode_size'], postprocess_minimal=True, n_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_df[square_df['beam_idx']==0]['correct_factorization'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cube_df = metrics_utils.form_factor_df(model, t, device, args['data']['base'], cubes, args['model_args']['max_decode_size'], postprocess_minimal=True, n_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_df[cube_df['beam_idx']==0]['correct_factorization'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_num</th>\n",
       "      <th>beam_idx</th>\n",
       "      <th>log_prob</th>\n",
       "      <th>pred_factor_list</th>\n",
       "      <th>product</th>\n",
       "      <th>correct_product</th>\n",
       "      <th>correct_factorization</th>\n",
       "      <th>target_is_prime</th>\n",
       "      <th>input_string</th>\n",
       "      <th>pred_list</th>\n",
       "      <th>pred_str</th>\n",
       "      <th>target_str</th>\n",
       "      <th>target_factor_list</th>\n",
       "      <th>n_target_factors</th>\n",
       "      <th>n_pred_factors</th>\n",
       "      <th>num_prime_factors_pred</th>\n",
       "      <th>percent_prime_factors_pred</th>\n",
       "      <th>pred_same_as_target</th>\n",
       "      <th>min_target_prime_factor_if_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1495729</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.320875</td>\n",
       "      <td>[62323]</td>\n",
       "      <td>62323</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[4, 12, 4, 19]]</td>\n",
       "      <td>&gt; 4 12 4 19 . _ _ _ _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1495729</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.600385</td>\n",
       "      <td>[23, 2741]</td>\n",
       "      <td>63043</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[23], [4, 18, 5]]</td>\n",
       "      <td>&gt; 23 x 4 18 5 . _ _ _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1495729</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.397596</td>\n",
       "      <td>[5, 47, 257]</td>\n",
       "      <td>60395</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [1, 23], [10, 17]]</td>\n",
       "      <td>&gt; 5 x 1 23 x 10 17 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1495729</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.501613</td>\n",
       "      <td>[5, 67, 229]</td>\n",
       "      <td>76715</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [2, 19], [9, 13]]</td>\n",
       "      <td>&gt; 5 x 2 19 x 9 13 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1495729</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.868195</td>\n",
       "      <td>[5, 53, 227]</td>\n",
       "      <td>60155</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [2, 5], [9, 11]]</td>\n",
       "      <td>&gt; 5 x 2 5 x 9 11 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1495729</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.881566</td>\n",
       "      <td>[73, 2347]</td>\n",
       "      <td>171331</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[3, 1], [4, 1, 19]]</td>\n",
       "      <td>&gt; 3 1 x 4 1 19 . _ _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1495729</td>\n",
       "      <td>6</td>\n",
       "      <td>-5.966593</td>\n",
       "      <td>[5, 53, 235]</td>\n",
       "      <td>62275</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [2, 5], [9, 19]]</td>\n",
       "      <td>&gt; 5 x 2 5 x 9 19 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1495729</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.081643</td>\n",
       "      <td>[5, 7, 1921]</td>\n",
       "      <td>67235</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [7], [3, 8, 1]]</td>\n",
       "      <td>&gt; 5 x 7 x 3 8 1 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1495729</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.114621</td>\n",
       "      <td>[37, 53, 83]</td>\n",
       "      <td>162763</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[1, 13], [2, 5], [3, 11]]</td>\n",
       "      <td>&gt; 1 13 x 2 5 x 3 11 . _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1495729</td>\n",
       "      <td>9</td>\n",
       "      <td>-6.123154</td>\n",
       "      <td>[5, 43, 349]</td>\n",
       "      <td>75035</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [1, 19], [14, 13]]</td>\n",
       "      <td>&gt; 5 x 1 19 x 14 13 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1495729</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.206448</td>\n",
       "      <td>[5, 71, 257]</td>\n",
       "      <td>91235</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [2, 23], [10, 17]]</td>\n",
       "      <td>&gt; 5 x 2 23 x 10 17 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1495729</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.300583</td>\n",
       "      <td>[5, 61, 283]</td>\n",
       "      <td>86315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [2, 13], [11, 19]]</td>\n",
       "      <td>&gt; 5 x 2 13 x 11 19 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1495729</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.349010</td>\n",
       "      <td>[5, 5, 2377]</td>\n",
       "      <td>59425</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [5], [4, 3, 1]]</td>\n",
       "      <td>&gt; 5 x 5 x 4 3 1 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1495729</td>\n",
       "      <td>13</td>\n",
       "      <td>-6.568032</td>\n",
       "      <td>[5, 67, 277]</td>\n",
       "      <td>92795</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [2, 19], [11, 13]]</td>\n",
       "      <td>&gt; 5 x 2 19 x 11 13 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1495729</td>\n",
       "      <td>14</td>\n",
       "      <td>-6.584673</td>\n",
       "      <td>[5, 71, 185]</td>\n",
       "      <td>65675</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [2, 23], [7, 17]]</td>\n",
       "      <td>&gt; 5 x 2 23 x 7 17 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1495729</td>\n",
       "      <td>15</td>\n",
       "      <td>-6.627196</td>\n",
       "      <td>[5, 71, 233]</td>\n",
       "      <td>82715</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [2, 23], [9, 17]]</td>\n",
       "      <td>&gt; 5 x 2 23 x 9 17 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1495729</td>\n",
       "      <td>16</td>\n",
       "      <td>-6.652529</td>\n",
       "      <td>[5, 43, 373]</td>\n",
       "      <td>80195</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [1, 19], [15, 13]]</td>\n",
       "      <td>&gt; 5 x 1 19 x 15 13 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1495729</td>\n",
       "      <td>17</td>\n",
       "      <td>-6.682624</td>\n",
       "      <td>[5, 47, 233]</td>\n",
       "      <td>54755</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [1, 23], [9, 17]]</td>\n",
       "      <td>&gt; 5 x 1 23 x 9 17 . _ _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1495729</td>\n",
       "      <td>18</td>\n",
       "      <td>-6.842156</td>\n",
       "      <td>[5, 7, 7, 7, 73]</td>\n",
       "      <td>125195</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [7], [7], [7], [3, 1]]</td>\n",
       "      <td>&gt; 5 x 7 x 7 x 7 x 3 1 . _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1495729</td>\n",
       "      <td>19</td>\n",
       "      <td>-6.892534</td>\n",
       "      <td>[5, 29, 769]</td>\n",
       "      <td>111505</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [1, 5], [1, 8, 1]]</td>\n",
       "      <td>&gt; 5 x 1 5 x 1 8 1 . _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1495729</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.892663</td>\n",
       "      <td>[5, 5, 7, 11, 55]</td>\n",
       "      <td>105875</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [5], [7], [11], [2, 7]]</td>\n",
       "      <td>&gt; 5 x 5 x 7 x 11 x 2 7 . _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1495729</td>\n",
       "      <td>21</td>\n",
       "      <td>-7.027591</td>\n",
       "      <td>[5, 31, 31, 31]</td>\n",
       "      <td>148955</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [1, 7], [1, 7], [1, 7]]</td>\n",
       "      <td>&gt; 5 x 1 7 x 1 7 x 1 7 . _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1495729</td>\n",
       "      <td>22</td>\n",
       "      <td>-7.486230</td>\n",
       "      <td>[37, 53, 73]</td>\n",
       "      <td>143153</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[1, 13], [2, 5], [3, 1]]</td>\n",
       "      <td>&gt; 1 13 x 2 5 x 3 1 . _ _ _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1495729</td>\n",
       "      <td>23</td>\n",
       "      <td>-8.132711</td>\n",
       "      <td>[5, 5, 5, 5, 5, 31]</td>\n",
       "      <td>96875</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [5], [5], [5], [5], [1, 7]]</td>\n",
       "      <td>&gt; 5 x 5 x 5 x 5 x 5 x 1 7 .</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1495729</td>\n",
       "      <td>24</td>\n",
       "      <td>-8.485646</td>\n",
       "      <td>[5, 7, 7, 7, 89]</td>\n",
       "      <td>152635</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[4, 12, 4, 18, 1]</td>\n",
       "      <td>[[5], [7], [7], [7], [3, 17]]</td>\n",
       "      <td>&gt; 5 x 7 x 7 x 7 x 3 17 . _ _</td>\n",
       "      <td>&gt; 2 2 23 x 2 2 23 .</td>\n",
       "      <td>[1223, 1223]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target_num  beam_idx  log_prob     pred_factor_list  product  \\\n",
       "0      1495729         0 -2.320875              [62323]    62323   \n",
       "1      1495729         1 -4.600385           [23, 2741]    63043   \n",
       "2      1495729         2 -5.397596         [5, 47, 257]    60395   \n",
       "3      1495729         3 -5.501613         [5, 67, 229]    76715   \n",
       "4      1495729         4 -5.868195         [5, 53, 227]    60155   \n",
       "5      1495729         5 -5.881566           [73, 2347]   171331   \n",
       "6      1495729         6 -5.966593         [5, 53, 235]    62275   \n",
       "7      1495729         7 -6.081643         [5, 7, 1921]    67235   \n",
       "8      1495729         8 -6.114621         [37, 53, 83]   162763   \n",
       "9      1495729         9 -6.123154         [5, 43, 349]    75035   \n",
       "10     1495729        10 -6.206448         [5, 71, 257]    91235   \n",
       "11     1495729        11 -6.300583         [5, 61, 283]    86315   \n",
       "12     1495729        12 -6.349010         [5, 5, 2377]    59425   \n",
       "13     1495729        13 -6.568032         [5, 67, 277]    92795   \n",
       "14     1495729        14 -6.584673         [5, 71, 185]    65675   \n",
       "15     1495729        15 -6.627196         [5, 71, 233]    82715   \n",
       "16     1495729        16 -6.652529         [5, 43, 373]    80195   \n",
       "17     1495729        17 -6.682624         [5, 47, 233]    54755   \n",
       "18     1495729        18 -6.842156     [5, 7, 7, 7, 73]   125195   \n",
       "19     1495729        19 -6.892534         [5, 29, 769]   111505   \n",
       "20     1495729        20 -6.892663    [5, 5, 7, 11, 55]   105875   \n",
       "21     1495729        21 -7.027591      [5, 31, 31, 31]   148955   \n",
       "22     1495729        22 -7.486230         [37, 53, 73]   143153   \n",
       "23     1495729        23 -8.132711  [5, 5, 5, 5, 5, 31]    96875   \n",
       "24     1495729        24 -8.485646     [5, 7, 7, 7, 89]   152635   \n",
       "\n",
       "    correct_product  correct_factorization  target_is_prime  \\\n",
       "0             False                  False            False   \n",
       "1             False                  False            False   \n",
       "2             False                  False            False   \n",
       "3             False                  False            False   \n",
       "4             False                  False            False   \n",
       "5             False                  False            False   \n",
       "6             False                  False            False   \n",
       "7             False                  False            False   \n",
       "8             False                  False            False   \n",
       "9             False                  False            False   \n",
       "10            False                  False            False   \n",
       "11            False                  False            False   \n",
       "12            False                  False            False   \n",
       "13            False                  False            False   \n",
       "14            False                  False            False   \n",
       "15            False                  False            False   \n",
       "16            False                  False            False   \n",
       "17            False                  False            False   \n",
       "18            False                  False            False   \n",
       "19            False                  False            False   \n",
       "20            False                  False            False   \n",
       "21            False                  False            False   \n",
       "22            False                  False            False   \n",
       "23            False                  False            False   \n",
       "24            False                  False            False   \n",
       "\n",
       "         input_string                          pred_list  \\\n",
       "0   [4, 12, 4, 18, 1]                   [[4, 12, 4, 19]]   \n",
       "1   [4, 12, 4, 18, 1]                 [[23], [4, 18, 5]]   \n",
       "2   [4, 12, 4, 18, 1]           [[5], [1, 23], [10, 17]]   \n",
       "3   [4, 12, 4, 18, 1]            [[5], [2, 19], [9, 13]]   \n",
       "4   [4, 12, 4, 18, 1]             [[5], [2, 5], [9, 11]]   \n",
       "5   [4, 12, 4, 18, 1]               [[3, 1], [4, 1, 19]]   \n",
       "6   [4, 12, 4, 18, 1]             [[5], [2, 5], [9, 19]]   \n",
       "7   [4, 12, 4, 18, 1]              [[5], [7], [3, 8, 1]]   \n",
       "8   [4, 12, 4, 18, 1]         [[1, 13], [2, 5], [3, 11]]   \n",
       "9   [4, 12, 4, 18, 1]           [[5], [1, 19], [14, 13]]   \n",
       "10  [4, 12, 4, 18, 1]           [[5], [2, 23], [10, 17]]   \n",
       "11  [4, 12, 4, 18, 1]           [[5], [2, 13], [11, 19]]   \n",
       "12  [4, 12, 4, 18, 1]              [[5], [5], [4, 3, 1]]   \n",
       "13  [4, 12, 4, 18, 1]           [[5], [2, 19], [11, 13]]   \n",
       "14  [4, 12, 4, 18, 1]            [[5], [2, 23], [7, 17]]   \n",
       "15  [4, 12, 4, 18, 1]            [[5], [2, 23], [9, 17]]   \n",
       "16  [4, 12, 4, 18, 1]           [[5], [1, 19], [15, 13]]   \n",
       "17  [4, 12, 4, 18, 1]            [[5], [1, 23], [9, 17]]   \n",
       "18  [4, 12, 4, 18, 1]       [[5], [7], [7], [7], [3, 1]]   \n",
       "19  [4, 12, 4, 18, 1]           [[5], [1, 5], [1, 8, 1]]   \n",
       "20  [4, 12, 4, 18, 1]      [[5], [5], [7], [11], [2, 7]]   \n",
       "21  [4, 12, 4, 18, 1]      [[5], [1, 7], [1, 7], [1, 7]]   \n",
       "22  [4, 12, 4, 18, 1]          [[1, 13], [2, 5], [3, 1]]   \n",
       "23  [4, 12, 4, 18, 1]  [[5], [5], [5], [5], [5], [1, 7]]   \n",
       "24  [4, 12, 4, 18, 1]      [[5], [7], [7], [7], [3, 17]]   \n",
       "\n",
       "                          pred_str           target_str target_factor_list  \\\n",
       "0    > 4 12 4 19 . _ _ _ _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "1    > 23 x 4 18 5 . _ _ _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "2   > 5 x 1 23 x 10 17 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "3    > 5 x 2 19 x 9 13 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "4     > 5 x 2 5 x 9 11 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "5     > 3 1 x 4 1 19 . _ _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "6     > 5 x 2 5 x 9 19 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "7      > 5 x 7 x 3 8 1 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "8    > 1 13 x 2 5 x 3 11 . _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "9   > 5 x 1 19 x 14 13 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "10  > 5 x 2 23 x 10 17 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "11  > 5 x 2 13 x 11 19 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "12     > 5 x 5 x 4 3 1 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "13  > 5 x 2 19 x 11 13 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "14   > 5 x 2 23 x 7 17 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "15   > 5 x 2 23 x 9 17 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "16  > 5 x 1 19 x 15 13 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "17   > 5 x 1 23 x 9 17 . _ _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "18     > 5 x 7 x 7 x 7 x 3 1 . _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "19     > 5 x 1 5 x 1 8 1 . _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "20    > 5 x 5 x 7 x 11 x 2 7 . _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "21     > 5 x 1 7 x 1 7 x 1 7 . _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "22    > 1 13 x 2 5 x 3 1 . _ _ _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "23     > 5 x 5 x 5 x 5 x 5 x 1 7 .  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "24    > 5 x 7 x 7 x 7 x 3 17 . _ _  > 2 2 23 x 2 2 23 .       [1223, 1223]   \n",
       "\n",
       "    n_target_factors  n_pred_factors  num_prime_factors_pred  \\\n",
       "0                  2               1                       1   \n",
       "1                  2               2                       2   \n",
       "2                  2               3                       3   \n",
       "3                  2               3                       3   \n",
       "4                  2               3                       3   \n",
       "5                  2               2                       2   \n",
       "6                  2               3                       2   \n",
       "7                  2               3                       2   \n",
       "8                  2               3                       3   \n",
       "9                  2               3                       3   \n",
       "10                 2               3                       3   \n",
       "11                 2               3                       3   \n",
       "12                 2               3                       3   \n",
       "13                 2               3                       3   \n",
       "14                 2               3                       2   \n",
       "15                 2               3                       3   \n",
       "16                 2               3                       3   \n",
       "17                 2               3                       3   \n",
       "18                 2               5                       5   \n",
       "19                 2               3                       3   \n",
       "20                 2               5                       4   \n",
       "21                 2               4                       4   \n",
       "22                 2               3                       3   \n",
       "23                 2               6                       6   \n",
       "24                 2               5                       5   \n",
       "\n",
       "    percent_prime_factors_pred  pred_same_as_target  \\\n",
       "0                     1.000000                False   \n",
       "1                     1.000000                False   \n",
       "2                     1.000000                False   \n",
       "3                     1.000000                False   \n",
       "4                     1.000000                False   \n",
       "5                     1.000000                False   \n",
       "6                     0.666667                False   \n",
       "7                     0.666667                False   \n",
       "8                     1.000000                False   \n",
       "9                     1.000000                False   \n",
       "10                    1.000000                False   \n",
       "11                    1.000000                False   \n",
       "12                    1.000000                False   \n",
       "13                    1.000000                False   \n",
       "14                    0.666667                False   \n",
       "15                    1.000000                False   \n",
       "16                    1.000000                False   \n",
       "17                    1.000000                False   \n",
       "18                    1.000000                False   \n",
       "19                    1.000000                False   \n",
       "20                    0.800000                False   \n",
       "21                    1.000000                False   \n",
       "22                    1.000000                False   \n",
       "23                    1.000000                False   \n",
       "24                    1.000000                False   \n",
       "\n",
       "    min_target_prime_factor_if_composite  \n",
       "0                                   1223  \n",
       "1                                   1223  \n",
       "2                                   1223  \n",
       "3                                   1223  \n",
       "4                                   1223  \n",
       "5                                   1223  \n",
       "6                                   1223  \n",
       "7                                   1223  \n",
       "8                                   1223  \n",
       "9                                   1223  \n",
       "10                                  1223  \n",
       "11                                  1223  \n",
       "12                                  1223  \n",
       "13                                  1223  \n",
       "14                                  1223  \n",
       "15                                  1223  \n",
       "16                                  1223  \n",
       "17                                  1223  \n",
       "18                                  1223  \n",
       "19                                  1223  \n",
       "20                                  1223  \n",
       "21                                  1223  \n",
       "22                                  1223  \n",
       "23                                  1223  \n",
       "24                                  1223  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_utils.factor(test_num, args['data']['base'], model, t, device, args['model_args']['max_decode_size'], n_beams=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
