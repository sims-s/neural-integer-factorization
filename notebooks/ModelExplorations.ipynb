{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import models\n",
    "import generation_utils\n",
    "import metrics_utils\n",
    "import tokenizer\n",
    "import data_utils\n",
    "from utils import get_best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 999)\n",
    "pd.set_option('display.max_rows', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../models/base_24_2^18/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model at ../models/base_24_2^18/checkpoints/730000_0.1004.pt\n"
     ]
    }
   ],
   "source": [
    "checkpoint = get_best_checkpoint(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = checkpoint['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer.Tokenizer(base = args['data']['base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'model_args', 'optimizer', 'scheduler', 'loader', 'io', 'metrics', 'multi_gpu', 'verbose', 'tokenizer'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Factorizer(\n",
       "  (embedding): TransformerEmbedding(\n",
       "    (embedding): Embedding(28, 128)\n",
       "    (pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (tokens_out): Linear(in_features=128, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Factorizer(n_tokens = args['tokenizer']['n_tokens'], \n",
    "                          pad_token_id = args['tokenizer']['pad_token_id'],\n",
    "                          **args['model_args'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.embedding.embedding.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [''.join(t.decode([i], decode_special=True)) for i in range(len(t))]\n",
    "special_tokens = set(['x', '_', '>', '.'])\n",
    "tokens = np.array([tok if tok in special_tokens else data_utils.base2dec([int(tok)], args['data']['base']) for tok in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
       "       'x', '_', '.', '>'], dtype='<U11')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE\n",
    "* Doesn't seem to be super interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=30, learning_rate=200, n_iter=1000)\n",
    "embeddings_for_plot = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(embeddings_for_plot[:,0], embeddings_for_plot[:,1])\n",
    "ax = plt.gca()\n",
    "for tok, (x,y) in zip(tokens, embeddings_for_plot):\n",
    "    fontsize = 12 if not tok in ['.', '_'] else 24\n",
    "    ax.annotate(tok, (x+.3,y), fontsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "* Some embeddings have relatively simlar cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_sim_mat = cosine_similarity(embeddings)\n",
    "cs_sims = np.triu(cs_sim_mat, 1).ravel()\n",
    "cs_sims = cs_sims[~np.isclose(cs_sims, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('cosine simiarlty of embeddings')\n",
    "pd.Series(cs_sims).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_sim_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat_show_mat = cs_sim_mat[:-4,:-4]\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 20)\n",
    "ax = plt.gca()\n",
    "plt.colorbar(ax.matshow(np.clip(mat_show_mat, a_min=-1, a_max=mat_show_mat[mat_show_mat<.99].max()*1.1)), ax=ax)\n",
    "ax.set_xticks(np.arange(mat_show_mat.shape[0]))\n",
    "ax.set_yticks(np.arange(mat_show_mat.shape[0]))\n",
    "ax.set_xticklabels(tokens[:mat_show_mat.shape[0]])\n",
    "ax.set_yticklabels(tokens[:mat_show_mat.shape[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0999999344348907"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_sim_mat[cs_sim_mat<1].max()*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C = .1, penalty='l1', solver='liblinear')\n",
    "# logreg = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 128), (28,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_x = embeddings[:-4]\n",
    "logreg_y = tokens[:-4].astype(int) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexer = np.random.rand(logreg_x.shape[0]) < .8\n",
    "logreg_x_train = logreg_x[train_indexer]\n",
    "logreg_x_test = logreg_x[~train_indexer]\n",
    "\n",
    "logreg_y_train = logreg_y[train_indexer]\n",
    "logreg_y_test = logreg_y[~train_indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23, 128), (23,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_x_train.shape, logreg_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 128), (1,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_x_test.shape, logreg_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(logreg_x_train, logreg_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(logreg_x_test, logreg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How well does the model do on numbers higher than what it was trained on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2**18\n",
    "length = 100\n",
    "numbers = np.arange(start, start + length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generation_utils' from '../src\\\\generation_utils.py'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(metrics_utils)\n",
    "importlib.reload(generation_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizer.Tokenizer at 0x24c4537ebb0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "larger_df = metrics_utils.form_factor_df(model, t, device, args['data']['base'], numbers, args['model_args']['max_decode_size'], postprocess_minimal=True, n_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larger_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_num</th>\n",
       "      <th>beam_idx</th>\n",
       "      <th>log_prob</th>\n",
       "      <th>pred_factor_list</th>\n",
       "      <th>product</th>\n",
       "      <th>correct_product</th>\n",
       "      <th>correct_factorization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262144</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.732651</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 107]</td>\n",
       "      <td>219136</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262144</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.737670</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 11, 11]</td>\n",
       "      <td>247808</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262144</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.973492</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5]</td>\n",
       "      <td>256000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262144</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.054171</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 13]</td>\n",
       "      <td>186368</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262144</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.356747</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 17]</td>\n",
       "      <td>243712</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_num  beam_idx  log_prob                            pred_factor_list  \\\n",
       "0      262144         0 -2.732651      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 107]   \n",
       "1      262144         1 -2.737670   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 11, 11]   \n",
       "2      262144         2 -2.973492  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5]   \n",
       "3      262144         3 -3.054171    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 13]   \n",
       "4      262144         4 -3.356747    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 17]   \n",
       "\n",
       "   product  correct_product  correct_factorization  \n",
       "0   219136            False                  False  \n",
       "1   247808            False                  False  \n",
       "2   256000            False                  False  \n",
       "3   186368            False                  False  \n",
       "4   243712            False                  False  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larger_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct_factorization    0.611\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larger_df.groupby('target_num').agg({'correct_factorization' : 'any'}).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.519"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_beams = larger_df['beam_idx'] == 9\n",
    "(larger_df[top_beams]['product'] < larger_df[top_beams]['target_num']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function generation_utils.factor(number, base, model, tokenizer, device, max_decode_size, n_beams=1, temperature=1.0, return_type='df', postprocess_minimal=False)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_utils.factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import factorint\n",
    "from sympy.ntheory import primerange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  9, 25, 49], dtype=int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(primerange(2, 10)))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = 1223*1223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1223: 2}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorint(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.774590832114356"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(448451)/np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_num</th>\n",
       "      <th>beam_idx</th>\n",
       "      <th>log_prob</th>\n",
       "      <th>pred_factor_list</th>\n",
       "      <th>product</th>\n",
       "      <th>correct_product</th>\n",
       "      <th>correct_factorization</th>\n",
       "      <th>target_is_prime</th>\n",
       "      <th>input_string</th>\n",
       "      <th>pred_list</th>\n",
       "      <th>pred_str</th>\n",
       "      <th>target_str</th>\n",
       "      <th>target_factor_list</th>\n",
       "      <th>n_target_factors</th>\n",
       "      <th>n_pred_factors</th>\n",
       "      <th>num_prime_factors_pred</th>\n",
       "      <th>percent_prime_factors_pred</th>\n",
       "      <th>pred_same_as_target</th>\n",
       "      <th>min_target_prime_factor_if_composite</th>\n",
       "      <th>lev_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>444841</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.526956</td>\n",
       "      <td>[60001]</td>\n",
       "      <td>60001</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[4, 8, 4, 1]]</td>\n",
       "      <td>&gt; 4 8 4 1 . _ _ _ _ _ _</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>444841</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.367818</td>\n",
       "      <td>[60007]</td>\n",
       "      <td>60007</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[4, 8, 4, 7]]</td>\n",
       "      <td>&gt; 4 8 4 7 . _ _ _ _ _ _</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>444841</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.399067</td>\n",
       "      <td>[239713]</td>\n",
       "      <td>239713</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[17, 8, 4, 1]]</td>\n",
       "      <td>&gt; 17 8 4 1 . _ _ _ _ _ _</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444841</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.577717</td>\n",
       "      <td>[239719]</td>\n",
       "      <td>239719</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[17, 8, 4, 7]]</td>\n",
       "      <td>&gt; 17 8 4 7 . _ _ _ _ _ _</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>444841</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.635875</td>\n",
       "      <td>[5, 29, 673]</td>\n",
       "      <td>97585</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[5], [1, 5], [1, 4, 1]]</td>\n",
       "      <td>&gt; 5 x 1 5 x 1 4 1 . _ _</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>444841</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.928322</td>\n",
       "      <td>[5, 43, 353]</td>\n",
       "      <td>75895</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[5], [1, 19], [14, 17]]</td>\n",
       "      <td>&gt; 5 x 1 19 x 14 17 . _ _ _</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>444841</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.758257</td>\n",
       "      <td>[5, 5, 7, 7, 83]</td>\n",
       "      <td>101675</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[5], [5], [7], [7], [3, 11]]</td>\n",
       "      <td>&gt; 5 x 5 x 7 x 7 x 3 11 .</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>444841</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.775347</td>\n",
       "      <td>[5, 43, 311]</td>\n",
       "      <td>66865</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[5], [1, 19], [12, 23]]</td>\n",
       "      <td>&gt; 5 x 1 19 x 12 23 . _ _ _</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>444841</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.171434</td>\n",
       "      <td>[5, 5, 5, 5, 97]</td>\n",
       "      <td>60625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[5], [5], [5], [5], [4, 1]]</td>\n",
       "      <td>&gt; 5 x 5 x 5 x 5 x 4 1 .</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>444841</td>\n",
       "      <td>9</td>\n",
       "      <td>-8.371604</td>\n",
       "      <td>[5, 5, 5, 701]</td>\n",
       "      <td>87625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 8, 4, 7, 1]</td>\n",
       "      <td>[[5], [5], [5], [1, 5, 5]]</td>\n",
       "      <td>&gt; 5 x 5 x 5 x 1 5 5 . _</td>\n",
       "      <td>&gt; 1 8 4 7 1 .</td>\n",
       "      <td>[444841]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_num  beam_idx  log_prob  pred_factor_list  product  correct_product  \\\n",
       "0      444841         0 -2.526956           [60001]    60001            False   \n",
       "1      444841         1 -3.367818           [60007]    60007            False   \n",
       "2      444841         2 -4.399067          [239713]   239713            False   \n",
       "3      444841         3 -4.577717          [239719]   239719            False   \n",
       "4      444841         4 -5.635875      [5, 29, 673]    97585            False   \n",
       "5      444841         5 -5.928322      [5, 43, 353]    75895            False   \n",
       "6      444841         6 -6.758257  [5, 5, 7, 7, 83]   101675            False   \n",
       "7      444841         7 -6.775347      [5, 43, 311]    66865            False   \n",
       "8      444841         8 -7.171434  [5, 5, 5, 5, 97]    60625            False   \n",
       "9      444841         9 -8.371604    [5, 5, 5, 701]    87625            False   \n",
       "\n",
       "   correct_factorization  target_is_prime     input_string  \\\n",
       "0                  False             True  [1, 8, 4, 7, 1]   \n",
       "1                  False             True  [1, 8, 4, 7, 1]   \n",
       "2                  False             True  [1, 8, 4, 7, 1]   \n",
       "3                  False             True  [1, 8, 4, 7, 1]   \n",
       "4                  False             True  [1, 8, 4, 7, 1]   \n",
       "5                  False             True  [1, 8, 4, 7, 1]   \n",
       "6                  False             True  [1, 8, 4, 7, 1]   \n",
       "7                  False             True  [1, 8, 4, 7, 1]   \n",
       "8                  False             True  [1, 8, 4, 7, 1]   \n",
       "9                  False             True  [1, 8, 4, 7, 1]   \n",
       "\n",
       "                       pred_list                    pred_str     target_str  \\\n",
       "0                 [[4, 8, 4, 1]]     > 4 8 4 1 . _ _ _ _ _ _  > 1 8 4 7 1 .   \n",
       "1                 [[4, 8, 4, 7]]     > 4 8 4 7 . _ _ _ _ _ _  > 1 8 4 7 1 .   \n",
       "2                [[17, 8, 4, 1]]    > 17 8 4 1 . _ _ _ _ _ _  > 1 8 4 7 1 .   \n",
       "3                [[17, 8, 4, 7]]    > 17 8 4 7 . _ _ _ _ _ _  > 1 8 4 7 1 .   \n",
       "4       [[5], [1, 5], [1, 4, 1]]     > 5 x 1 5 x 1 4 1 . _ _  > 1 8 4 7 1 .   \n",
       "5       [[5], [1, 19], [14, 17]]  > 5 x 1 19 x 14 17 . _ _ _  > 1 8 4 7 1 .   \n",
       "6  [[5], [5], [7], [7], [3, 11]]    > 5 x 5 x 7 x 7 x 3 11 .  > 1 8 4 7 1 .   \n",
       "7       [[5], [1, 19], [12, 23]]  > 5 x 1 19 x 12 23 . _ _ _  > 1 8 4 7 1 .   \n",
       "8   [[5], [5], [5], [5], [4, 1]]     > 5 x 5 x 5 x 5 x 4 1 .  > 1 8 4 7 1 .   \n",
       "9     [[5], [5], [5], [1, 5, 5]]     > 5 x 5 x 5 x 1 5 5 . _  > 1 8 4 7 1 .   \n",
       "\n",
       "  target_factor_list  n_target_factors  n_pred_factors  \\\n",
       "0           [444841]                 1               1   \n",
       "1           [444841]                 1               1   \n",
       "2           [444841]                 1               1   \n",
       "3           [444841]                 1               1   \n",
       "4           [444841]                 1               3   \n",
       "5           [444841]                 1               3   \n",
       "6           [444841]                 1               5   \n",
       "7           [444841]                 1               3   \n",
       "8           [444841]                 1               5   \n",
       "9           [444841]                 1               4   \n",
       "\n",
       "   num_prime_factors_pred  percent_prime_factors_pred  pred_same_as_target  \\\n",
       "0                       0                         0.0                False   \n",
       "1                       0                         0.0                False   \n",
       "2                       1                         1.0                False   \n",
       "3                       0                         0.0                False   \n",
       "4                       3                         1.0                False   \n",
       "5                       3                         1.0                False   \n",
       "6                       5                         1.0                False   \n",
       "7                       3                         1.0                False   \n",
       "8                       5                         1.0                False   \n",
       "9                       4                         1.0                False   \n",
       "\n",
       "   min_target_prime_factor_if_composite  lev_dist  \n",
       "0                                    -1         3  \n",
       "1                                    -1         3  \n",
       "2                                    -1         3  \n",
       "3                                    -1         3  \n",
       "4                                    -1         9  \n",
       "5                                    -1        10  \n",
       "6                                    -1        14  \n",
       "7                                    -1        11  \n",
       "8                                    -1        14  \n",
       "9                                    -1        12  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = metrics_utils.form_factor_df(model, t, device, args['data']['base'], np.array([444841]), args['model_args']['max_decode_size'], postprocess_minimal=False, n_beams = 10)\n",
    "num_df['lev_dist'] = num_df.apply(lambda x: Levenshtein.distance(x['pred_str'].replace(' _', ''), x['target_str']), axis=1)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how does it handle squares/cubes/...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 256\n",
    "squares = np.array(list(primerange(2, max_num)))**2\n",
    "cubes = np.array(list(primerange(2, max_num)))**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "square_df = metrics_utils.form_factor_df(model, t, device, args['data']['base'], squares, args['model_args']['max_decode_size'], postprocess_minimal=True, n_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6296296296296297"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_df[square_df['beam_idx']==0]['correct_factorization'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cube_df = metrics_utils.form_factor_df(model, t, device, args['data']['base'], cubes, args['model_args']['max_decode_size'], postprocess_minimal=True, n_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18518518518518517"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_df[cube_df['beam_idx']==0]['correct_factorization'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When encoding two different numbers, what are the cosine similarities of their representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_int = 16\n",
    "second_int = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reps_for_number(number):\n",
    "    tokens = t.encode(data_utils.form_input(number, args['data']['base']))\n",
    "    tens = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    memory, _ = model.encode(tens)\n",
    "    return memory.squeeze().data.cpu().numpy(), tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_reps, first_tokens = get_reps_for_number(first_int)\n",
    "second_reps, second_tokens = get_reps_for_number(second_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_sims = cosine_similarity(first_reps, second_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8,8)\n",
    "ax = plt.gca()\n",
    "plt.colorbar(ax.matshow(cs_sims), ax=ax)\n",
    "ax.set_xticks(np.arange(cs_sims.shape[1]))\n",
    "ax.set_yticks(np.arange(cs_sims.shape[0]))\n",
    "ax.set_xticklabels(t.decode(second_tokens, decode_special=True).split(' '))\n",
    "ax.set_yticklabels(t.decode(first_tokens, decode_special=True).split(' '))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When the model gets it wrong, what is the probability of the right sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_num = 277337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_num</th>\n",
       "      <th>beam_idx</th>\n",
       "      <th>log_prob</th>\n",
       "      <th>pred_factor_list</th>\n",
       "      <th>product</th>\n",
       "      <th>correct_product</th>\n",
       "      <th>correct_factorization</th>\n",
       "      <th>target_is_prime</th>\n",
       "      <th>input_string</th>\n",
       "      <th>pred_list</th>\n",
       "      <th>pred_str</th>\n",
       "      <th>target_str</th>\n",
       "      <th>target_factor_list</th>\n",
       "      <th>n_target_factors</th>\n",
       "      <th>n_pred_factors</th>\n",
       "      <th>num_prime_factors_pred</th>\n",
       "      <th>percent_prime_factors_pred</th>\n",
       "      <th>pred_same_as_target</th>\n",
       "      <th>min_target_prime_factor_if_composite</th>\n",
       "      <th>lev_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277337</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.147279</td>\n",
       "      <td>[5, 113, 341]</td>\n",
       "      <td>192665</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[5], [4, 17], [14, 5]]</td>\n",
       "      <td>&gt; 5 x 4 17 x 14 5 . _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>277337</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.211429</td>\n",
       "      <td>[5, 107, 527]</td>\n",
       "      <td>281945</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[5], [4, 11], [21, 23]]</td>\n",
       "      <td>&gt; 5 x 4 11 x 21 23 . _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277337</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.589801</td>\n",
       "      <td>[5, 101, 401]</td>\n",
       "      <td>202505</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[5], [4, 5], [16, 17]]</td>\n",
       "      <td>&gt; 5 x 4 5 x 16 17 . _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>277337</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.629195</td>\n",
       "      <td>[5, 97, 421]</td>\n",
       "      <td>204185</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[5], [4, 1], [17, 13]]</td>\n",
       "      <td>&gt; 5 x 4 1 x 17 13 . _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277337</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.711498</td>\n",
       "      <td>[17, 15433]</td>\n",
       "      <td>262361</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[17], [1, 2, 19, 1]]</td>\n",
       "      <td>&gt; 17 x 1 2 19 1 . _ _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>277337</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.869519</td>\n",
       "      <td>[11, 43, 553]</td>\n",
       "      <td>261569</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[11], [1, 19], [23, 1]]</td>\n",
       "      <td>&gt; 11 x 1 19 x 23 1 . _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>277337</td>\n",
       "      <td>6</td>\n",
       "      <td>-3.960406</td>\n",
       "      <td>[23, 11983]</td>\n",
       "      <td>275609</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[23], [20, 19, 7]]</td>\n",
       "      <td>&gt; 23 x 20 19 7 . _ _ _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>277337</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.139458</td>\n",
       "      <td>[5, 109, 553]</td>\n",
       "      <td>301385</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[5], [4, 13], [23, 1]]</td>\n",
       "      <td>&gt; 5 x 4 13 x 23 1 . _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>277337</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.495574</td>\n",
       "      <td>[5, 109, 457]</td>\n",
       "      <td>249065</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[5], [4, 13], [19, 1]]</td>\n",
       "      <td>&gt; 5 x 4 13 x 19 1 . _ _</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>277337</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.240434</td>\n",
       "      <td>[7, 7, 7, 743]</td>\n",
       "      <td>254849</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 1, 11, 17]</td>\n",
       "      <td>[[7], [7], [7], [1, 6, 23]]</td>\n",
       "      <td>&gt; 7 x 7 x 7 x 1 6 23 .</td>\n",
       "      <td>&gt; 19 7 x 1 0 23 .</td>\n",
       "      <td>[463, 599]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>463</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_num  beam_idx  log_prob pred_factor_list  product  correct_product  \\\n",
       "0      277337         0 -3.147279    [5, 113, 341]   192665            False   \n",
       "1      277337         1 -3.211429    [5, 107, 527]   281945            False   \n",
       "2      277337         2 -3.589801    [5, 101, 401]   202505            False   \n",
       "3      277337         3 -3.629195     [5, 97, 421]   204185            False   \n",
       "4      277337         4 -3.711498      [17, 15433]   262361            False   \n",
       "5      277337         5 -3.869519    [11, 43, 553]   261569            False   \n",
       "6      277337         6 -3.960406      [23, 11983]   275609            False   \n",
       "7      277337         7 -4.139458    [5, 109, 553]   301385            False   \n",
       "8      277337         8 -4.495574    [5, 109, 457]   249065            False   \n",
       "9      277337         9 -5.240434   [7, 7, 7, 743]   254849            False   \n",
       "\n",
       "   correct_factorization  target_is_prime     input_string  \\\n",
       "0                  False            False  [20, 1, 11, 17]   \n",
       "1                  False            False  [20, 1, 11, 17]   \n",
       "2                  False            False  [20, 1, 11, 17]   \n",
       "3                  False            False  [20, 1, 11, 17]   \n",
       "4                  False            False  [20, 1, 11, 17]   \n",
       "5                  False            False  [20, 1, 11, 17]   \n",
       "6                  False            False  [20, 1, 11, 17]   \n",
       "7                  False            False  [20, 1, 11, 17]   \n",
       "8                  False            False  [20, 1, 11, 17]   \n",
       "9                  False            False  [20, 1, 11, 17]   \n",
       "\n",
       "                     pred_list                  pred_str         target_str  \\\n",
       "0      [[5], [4, 17], [14, 5]]   > 5 x 4 17 x 14 5 . _ _  > 19 7 x 1 0 23 .   \n",
       "1     [[5], [4, 11], [21, 23]]  > 5 x 4 11 x 21 23 . _ _  > 19 7 x 1 0 23 .   \n",
       "2      [[5], [4, 5], [16, 17]]   > 5 x 4 5 x 16 17 . _ _  > 19 7 x 1 0 23 .   \n",
       "3      [[5], [4, 1], [17, 13]]   > 5 x 4 1 x 17 13 . _ _  > 19 7 x 1 0 23 .   \n",
       "4        [[17], [1, 2, 19, 1]]   > 17 x 1 2 19 1 . _ _ _  > 19 7 x 1 0 23 .   \n",
       "5     [[11], [1, 19], [23, 1]]  > 11 x 1 19 x 23 1 . _ _  > 19 7 x 1 0 23 .   \n",
       "6          [[23], [20, 19, 7]]  > 23 x 20 19 7 . _ _ _ _  > 19 7 x 1 0 23 .   \n",
       "7      [[5], [4, 13], [23, 1]]   > 5 x 4 13 x 23 1 . _ _  > 19 7 x 1 0 23 .   \n",
       "8      [[5], [4, 13], [19, 1]]   > 5 x 4 13 x 19 1 . _ _  > 19 7 x 1 0 23 .   \n",
       "9  [[7], [7], [7], [1, 6, 23]]    > 7 x 7 x 7 x 1 6 23 .  > 19 7 x 1 0 23 .   \n",
       "\n",
       "  target_factor_list  n_target_factors  n_pred_factors  \\\n",
       "0         [463, 599]                 2               3   \n",
       "1         [463, 599]                 2               3   \n",
       "2         [463, 599]                 2               3   \n",
       "3         [463, 599]                 2               3   \n",
       "4         [463, 599]                 2               2   \n",
       "5         [463, 599]                 2               3   \n",
       "6         [463, 599]                 2               2   \n",
       "7         [463, 599]                 2               3   \n",
       "8         [463, 599]                 2               3   \n",
       "9         [463, 599]                 2               4   \n",
       "\n",
       "   num_prime_factors_pred  percent_prime_factors_pred  pred_same_as_target  \\\n",
       "0                       2                    0.666667                False   \n",
       "1                       2                    0.666667                False   \n",
       "2                       3                    1.000000                False   \n",
       "3                       3                    1.000000                False   \n",
       "4                       1                    0.500000                False   \n",
       "5                       2                    0.666667                False   \n",
       "6                       1                    0.500000                False   \n",
       "7                       2                    0.666667                False   \n",
       "8                       3                    1.000000                False   \n",
       "9                       4                    1.000000                False   \n",
       "\n",
       "   min_target_prime_factor_if_composite  lev_dist  \n",
       "0                                   463        10  \n",
       "1                                   463         9  \n",
       "2                                   463        10  \n",
       "3                                   463         9  \n",
       "4                                   463         7  \n",
       "5                                   463         7  \n",
       "6                                   463         9  \n",
       "7                                   463         8  \n",
       "8                                   463        10  \n",
       "9                                   463         8  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = metrics_utils.form_factor_df(model, t, device, args['data']['base'], np.array([target_num]), args['model_args']['max_decode_size'], postprocess_minimal=False, n_beams = 10)\n",
    "num_df['lev_dist'] = num_df.apply(lambda x: Levenshtein.distance(x['pred_str'].replace(' _', ''), x['target_str']), axis=1)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>', 19, 7, 'x', 1, 0, 23, '.']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_utils.form_label(target_num, args['data']['base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_of_factorization(number, factorization):\n",
    "    tokens = t.encode(data_utils.form_input(number, args['data']['base']))\n",
    "    tensor_input = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    \n",
    "    factorization_input = torch.tensor(t.encode(factorization)).unsqueeze(0).to(device)\n",
    "    \n",
    "    model_output = torch.softmax(model(tensor_input, factorization_input).squeeze(0), dim=-1)\n",
    "    \n",
    "    probs = model_output[torch.arange(model_output.size(0)-1),factorization_input[0,1:]]\n",
    "    \n",
    "    return probs.log().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-22.5835, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_of_factorization(target_num, num_df.iloc[0]['target_str'].strip().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
