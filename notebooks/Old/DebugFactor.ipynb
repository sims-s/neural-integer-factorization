{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import models\n",
    "import generation_utils\n",
    "import tokenizer\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '../models/base_15/checkpoints/176_0.1316.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = checkpoint['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/2^16.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['data']['data_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.gfm = data_utils.GlobalFactorMapping(data_path = '.' + args['data']['data_loc'] if args['data']['data_loc'].endswith('.json') else \\\n",
    "                                          args['data']['data_loc'] + '2^%d.json'%args['data']['max_pow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer.Tokenizer(base = args['data']['base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'model_args', 'optimizer', 'scheduler', 'loader', 'io', 'metrics', 'verbose', 'tokenizer'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Factorizer(\n",
       "  (embedding): TransformerEmbedding(\n",
       "    (embedding): Embedding(19, 128)\n",
       "    (pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttentionAllHeads(\n",
       "            (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.05, inplace=False)\n",
       "          (dropout2): Dropout(p=0.05, inplace=False)\n",
       "          (dropout3): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (tokens_out): Linear(in_features=128, out_features=19, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Factorizer(n_tokens = args['tokenizer']['n_tokens'], \n",
    "                          pad_token_id = args['tokenizer']['pad_token_id'],\n",
    "                          **args['model_args'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generation_utils' from '../src\\\\generation_utils.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(generation_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = generation_utils.factor(17, args['data']['base'], model, t, device, args['model_args']['max_decode_size'], n_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_num</th>\n",
       "      <th>target_is_prime</th>\n",
       "      <th>input_string</th>\n",
       "      <th>target_str</th>\n",
       "      <th>target_factor_list</th>\n",
       "      <th>pred_str</th>\n",
       "      <th>beam_idx</th>\n",
       "      <th>log_prob</th>\n",
       "      <th>n_target_factors</th>\n",
       "      <th>pred_same_as_target</th>\n",
       "      <th>pred_factor_list</th>\n",
       "      <th>n_pred_factors</th>\n",
       "      <th>product</th>\n",
       "      <th>correct_product</th>\n",
       "      <th>correct_factorization</th>\n",
       "      <th>num_prime_factors_pred</th>\n",
       "      <th>percent_prime_factors_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;12._____</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.275626</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>[17]</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;7x27.___</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.806215</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[7, 37]</td>\n",
       "      <td>2</td>\n",
       "      <td>259</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;Bx18.___</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.892918</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[11, 23]</td>\n",
       "      <td>2</td>\n",
       "      <td>253</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;Dx14.___</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.085363</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[13, 19]</td>\n",
       "      <td>2</td>\n",
       "      <td>247</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;27._____</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.773743</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[37]</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;2x2x2x2.</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.857347</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[2, 2, 2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;Bx3.____</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.615718</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[11, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;32._____</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.645571</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[47]</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;38._____</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.638335</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[53]</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;12.</td>\n",
       "      <td>[17]</td>\n",
       "      <td>&gt;21._____</td>\n",
       "      <td>9</td>\n",
       "      <td>-6.181497</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[31]</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_num  target_is_prime input_string target_str target_factor_list  \\\n",
       "0          17             True           12       >12.               [17]   \n",
       "1          17             True           12       >12.               [17]   \n",
       "2          17             True           12       >12.               [17]   \n",
       "3          17             True           12       >12.               [17]   \n",
       "4          17             True           12       >12.               [17]   \n",
       "5          17             True           12       >12.               [17]   \n",
       "6          17             True           12       >12.               [17]   \n",
       "7          17             True           12       >12.               [17]   \n",
       "8          17             True           12       >12.               [17]   \n",
       "9          17             True           12       >12.               [17]   \n",
       "\n",
       "    pred_str  beam_idx  log_prob  n_target_factors  pred_same_as_target  \\\n",
       "0  >12._____         0 -0.275626                 1                 True   \n",
       "1  >7x27.___         1 -2.806215                 1                False   \n",
       "2  >Bx18.___         2 -2.892918                 1                False   \n",
       "3  >Dx14.___         3 -3.085363                 1                False   \n",
       "4  >27._____         4 -3.773743                 1                False   \n",
       "5  >2x2x2x2.         5 -3.857347                 1                False   \n",
       "6  >Bx3.____         6 -4.615718                 1                False   \n",
       "7  >32._____         7 -4.645571                 1                False   \n",
       "8  >38._____         8 -5.638335                 1                False   \n",
       "9  >21._____         9 -6.181497                 1                False   \n",
       "\n",
       "  pred_factor_list  n_pred_factors  product  correct_product  \\\n",
       "0             [17]               1       17             True   \n",
       "1          [7, 37]               2      259            False   \n",
       "2         [11, 23]               2      253            False   \n",
       "3         [13, 19]               2      247            False   \n",
       "4             [37]               1       37            False   \n",
       "5     [2, 2, 2, 2]               4       16            False   \n",
       "6          [11, 3]               2       33            False   \n",
       "7             [47]               1       47            False   \n",
       "8             [53]               1       53            False   \n",
       "9             [31]               1       31            False   \n",
       "\n",
       "   correct_factorization  num_prime_factors_pred  percent_prime_factors_pred  \n",
       "0                   True                       1                         1.0  \n",
       "1                  False                       2                         1.0  \n",
       "2                  False                       2                         1.0  \n",
       "3                  False                       2                         1.0  \n",
       "4                  False                       1                         1.0  \n",
       "5                  False                       4                         1.0  \n",
       "6                  False                       2                         1.0  \n",
       "7                  False                       1                         1.0  \n",
       "8                  False                       1                         1.0  \n",
       "9                  False                       1                         1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
