{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_colwidth', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = []\n",
    "metric_list = []\n",
    "\n",
    "for f in os.listdir(model_path):\n",
    "    subdir = model_path + f + '/'\n",
    "    config_path = subdir + 'config.yaml'\n",
    "    metrics_path = subdir + 'metrics.json'\n",
    "    \n",
    "    this_config = load_yaml(config_path)\n",
    "    for maybe_metrics_file in os.listdir(subdir):\n",
    "        if maybe_metrics_file.startswith('metrics') and maybe_metrics_file.endswith('.json'):\n",
    "            config_list.append(this_config)\n",
    "            metric_list.append(load_json(subdir + maybe_metrics_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config_list), len(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'base': 2, 'data_loc': './data/2^16.json', 'max_pow': 16},\n",
       " 'io': {'save_path': './models/base_2/'},\n",
       " 'loader': {'test': {'batch_size': 256, 'shuffle': False},\n",
       "  'train': {'batch_size': 64, 'shuffle': True}},\n",
       " 'metrics': {'max_num': -1, 'n_beams': 2, 'save_suffix': ''},\n",
       " 'model_args': {'dim_feedforward': 512,\n",
       "  'dropout': 0.05,\n",
       "  'embed_dim': 128,\n",
       "  'learn_positional_encoding': False,\n",
       "  'max_decode_size': 64,\n",
       "  'num_decoder_layers': 6,\n",
       "  'num_encoder_layers': 6,\n",
       "  'scale_embeddings': False,\n",
       "  'shared_embeddings': True},\n",
       " 'optimizer': {'max_grad_norm': 1, 'opt_args': {'lr': 0.001}, 'type': 'adam'},\n",
       " 'scheduler': {'n_warmup_steps': 10000,\n",
       "  'nb_epochs': 200,\n",
       "  'nb_steps': 164200,\n",
       "  'type': 'linear_schedule_with_warmup'},\n",
       " 'tokenizer': {'n_tokens': 6, 'pad_token_id': 3},\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_config_item(config_item):\n",
    "    expanded = {}\n",
    "    expanded['base'] = config_item['data']['base']\n",
    "    expanded['train_batch_size'] = config_item['loader']['train']['batch_size']\n",
    "    for k, v in config_item['model_args'].items():\n",
    "        expanded[k] = v\n",
    "    expanded['optimizer'] = config_item['optimizer']['type']\n",
    "    for k, v in config_item['optimizer']['opt_args'].items():\n",
    "        expanded[k] = v\n",
    "#     handle all model args\n",
    "#     handle all opt args\n",
    "    expanded['n_warmup_steps'] = config_item['scheduler']['n_warmup_steps']\n",
    "    expanded['nb_epochs'] = config_item['scheduler']['nb_epochs']\n",
    "    expanded['max_grad_norm'] = config_item['optimizer']['max_grad_norm']\n",
    "    expanded['learn_positional_encoding'] = config_item['model_args']['learn_positional_encoding']\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = [expand_config_item(c) for c in config_list]\n",
    "config_df = pd.DataFrame.from_dict(expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>dim_feedforward</th>\n",
       "      <th>dropout</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>learn_positional_encoding</th>\n",
       "      <th>max_decode_size</th>\n",
       "      <th>num_decoder_layers</th>\n",
       "      <th>num_encoder_layers</th>\n",
       "      <th>scale_embeddings</th>\n",
       "      <th>shared_embeddings</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_warmup_steps</th>\n",
       "      <th>nb_epochs</th>\n",
       "      <th>max_grad_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   base  train_batch_size  dim_feedforward  dropout  embed_dim  \\\n",
       "0     2                64              512     0.05        128   \n",
       "1     2                64              512     0.05        128   \n",
       "2     3                64              512     0.05        128   \n",
       "3     3                64              512     0.05        128   \n",
       "4     4                64              512     0.05        128   \n",
       "5     4                64              512     0.05        128   \n",
       "6     5                64              512     0.05        128   \n",
       "7     6                64              512     0.05        128   \n",
       "8     6                64              512     0.05        128   \n",
       "\n",
       "   learn_positional_encoding  max_decode_size  num_decoder_layers  \\\n",
       "0                      False               64                   6   \n",
       "1                      False               64                   6   \n",
       "2                      False               64                   6   \n",
       "3                      False               64                   6   \n",
       "4                      False               64                   6   \n",
       "5                      False               64                   6   \n",
       "6                      False               64                   6   \n",
       "7                      False               64                   6   \n",
       "8                      False               64                   6   \n",
       "\n",
       "   num_encoder_layers  scale_embeddings  shared_embeddings optimizer     lr  \\\n",
       "0                   6             False               True      adam  0.001   \n",
       "1                   6             False               True      adam  0.001   \n",
       "2                   6             False               True      adam  0.001   \n",
       "3                   6             False               True      adam  0.001   \n",
       "4                   6             False               True      adam  0.001   \n",
       "5                   6             False               True      adam  0.001   \n",
       "6                   6             False               True      adam  0.001   \n",
       "7                   6             False               True      adam  0.001   \n",
       "8                   6             False               True      adam  0.001   \n",
       "\n",
       "   n_warmup_steps  nb_epochs  max_grad_norm  \n",
       "0           10000        200              1  \n",
       "1           10000        200              1  \n",
       "2           10000        200              1  \n",
       "3           10000        200              1  \n",
       "4           10000        200              1  \n",
       "5           10000        200              1  \n",
       "6           10000        200              1  \n",
       "7           10000        200              1  \n",
       "8           10000        200              1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nice_metrics(metric_list):\n",
    "    correct = pd.DataFrame.from_dict([l['correct'] for l in metric_list])\n",
    "    n_beams = pd.DataFrame.from_dict([l['meta']['n_beams'] for l in metric_list])\n",
    "    n_beams.columns = ['n_beams']\n",
    "    \n",
    "    return [correct, n_beams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([config_df] + get_nice_metrics(metric_list), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all confiuraiton columns that have no variantion b/c that's not super helpful\n",
    "drop_cols = []\n",
    "for c in list(config_df) + ['n_beams']:\n",
    "    if merged[c].nunique()==1:\n",
    "        drop_cols.append(c)\n",
    "metric_df = merged.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>correct_product</th>\n",
       "      <th>correct_factorization</th>\n",
       "      <th>n_beams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.955059</td>\n",
       "      <td>0.398402</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>0.641085</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.878467</td>\n",
       "      <td>0.333026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.601598</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.937082</td>\n",
       "      <td>0.523162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>0.754782</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.410386</td>\n",
       "      <td>0.063225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0.955443</td>\n",
       "      <td>0.683414</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>0.825689</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   base  correct_product  correct_factorization  n_beams\n",
       "0     2         0.955059               0.398402        2\n",
       "1     2         0.999770               0.641085       10\n",
       "2     3         0.878467               0.333026        2\n",
       "3     3         0.999539               0.601598       10\n",
       "4     4         0.937082               0.523162        2\n",
       "5     4         0.999232               0.754782       10\n",
       "6     5         0.410386               0.063225        2\n",
       "7     6         0.955443               0.683414        2\n",
       "8     6         0.989091               0.825689       10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_different_values(df, col):\n",
    "    if isinstance(col, str):\n",
    "        col_list = [col]\n",
    "    else:\n",
    "        col_list = col\n",
    "    \n",
    "    \n",
    "    config_cols = ['num_encoder_layers', 'num_decoder_layers', 'input_padding', 'dim_feedforward', 'embed_dim', 'shared_embeddings', 'n_warmup_steps', 'nb_epochs', 'max_grad_norm']\n",
    "    metric_cols = [c for c in list(df) if not c in config_cols]\n",
    "    non_targets = [c for c in config_cols if not c in col_list]\n",
    "    df['other_str'] = df[non_targets].apply(lambda x: '_'.join([str(x[i]) for i in range(len(x))]), axis=1)\n",
    "    target_name = '_'.join(col_list)\n",
    "    df[target_name] = df[col_list].apply(lambda x: '_'.join([str(y) for y in x]), axis=1)\n",
    "\n",
    "    filtered = df.groupby('other_str').filter(lambda x: len(x) > 1)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "    ax[0,0].set_title('correct_product')\n",
    "    ax[0,1].set_title('correct_factorization')\n",
    "    ax[1,0].set_title('beam_0_product')\n",
    "    ax[1,1].set_title('beam_0_factorization')\n",
    "    \n",
    "    \n",
    "    n_levels = filtered[target_name].nunique()\n",
    "    label_mapper = {label:i for i, label in enumerate(df[target_name].unique())}\n",
    "    label_mapper_inv = {i : label for label, i in label_mapper.items()}\n",
    "#     print(label_mapper, label_mapper_inv)\n",
    "    filtered[target_name] = filtered[target_name].apply(lambda x: label_mapper[x])\n",
    "    filtered.set_index(target_name, inplace=True)\n",
    "    \n",
    "#     display(filtered)\n",
    "    \n",
    "    for title, group in filtered.groupby('other_str'):\n",
    "        group['correct_product'].plot(ax=ax[0,0], label=title, marker='x')\n",
    "        group['correct_factorization'].plot(ax=ax[0,1], label=title, marker='x')\n",
    "        group['beam_0_product'].plot(ax=ax[1,0], label=title, marker='x')\n",
    "        group['beam_0_factorization'].plot(ax=ax[1,1], label=title, marker='x')\n",
    "        \n",
    "        \n",
    "        for i in range(ax.shape[0]):\n",
    "            for j in range(ax.shape[1]):\n",
    "                ax[i,j].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "                ax[i,j].set_xticks(np.arange(n_levels))\n",
    "                ax[i,j].set_xticklabels([label_mapper_inv[i] for i in range(n_levels)])\n",
    "    fig.set_size_inches(14,8)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Type: Padding vs Zeros\n",
    "* Bascially the same performance for all cases. But pad always won.\n",
    "* So For future experiments, going to use pad instead of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_different_values(merged, 'input_padding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Embeddings for input/output\n",
    "* Same as above. Use shared embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_different_values(merged, 'shared_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models are a bit underfit. Using more epochs is helpful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_different_values(merged, ['nb_epochs', 'n_warmup_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_different_values(merged, ['num_encoder_layers', 'num_decoder_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_different_values(merged, 'max_grad_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_different_values(merged, 'learn_positional_encoding')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
